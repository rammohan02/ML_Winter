{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f9f9a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "becd949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading train and test data sets of mnist dataset\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "transforms = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "\n",
    "# download and create datasets\n",
    "trainset = datasets.MNIST(root='mnist_data', train=True, transform=transforms, download=True)\n",
    "\n",
    "testset = datasets.MNIST(root='mnist_data', train=False, transform=transforms)\n",
    "\n",
    "# define the data loaders\n",
    "trainloader = DataLoader(dataset=trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "testloader = DataLoader(dataset=testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27465e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8     1     2     0    \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35822a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Defining the Le-Net model for gray scale images with input channels as 1D not as 3D\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02dbce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Initializing loss finction and auto weight and bias updater\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "245ffe06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.449\n",
      "[1,  4000] loss: 0.285\n",
      "[1,  6000] loss: 0.179\n",
      "[1,  8000] loss: 0.134\n",
      "[1, 10000] loss: 0.118\n",
      "[1, 12000] loss: 0.111\n",
      "[1, 14000] loss: 0.106\n",
      "[2,  2000] loss: 0.085\n",
      "[2,  4000] loss: 0.079\n",
      "[2,  6000] loss: 0.072\n",
      "[2,  8000] loss: 0.068\n",
      "[2, 10000] loss: 0.070\n",
      "[2, 12000] loss: 0.060\n",
      "[2, 14000] loss: 0.057\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# loop over the dataset for two times\n",
    "for epoch in range(2):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "#         print(inputs)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a27712",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ba03d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  8     1     2     0    \n"
     ]
    }
   ],
   "source": [
    "# Printing the first 4 output or predicted classes\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a14c778d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on  10000  test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy of model on test dataset\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(\"Accuracy of the network on \", total ,\" test images:\", 100*correct//total, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9c431ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: 0     is 99.6 %\n",
      "Accuracy for class: 1     is 98.7 %\n",
      "Accuracy for class: 2     is 99.0 %\n",
      "Accuracy for class: 3     is 98.8 %\n",
      "Accuracy for class: 4     is 98.0 %\n",
      "Accuracy for class: 5     is 98.1 %\n",
      "Accuracy for class: 6     is 97.1 %\n",
      "Accuracy for class: 7     is 98.0 %\n",
      "Accuracy for class: 8     is 98.6 %\n",
      "Accuracy for class: 9     is 98.3 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec289b4",
   "metadata": {},
   "source": [
    "# Testing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11716a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Defining the Le-Net model for gray scale images with input channels as 1D not as 3D\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 10)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 10)\n",
    "        self.fc1 = nn.Linear(16 * 1 * 1, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d06f5b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Initializing loss finction and auto weight and bias updater\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bac13a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2000] loss: 1.410\n",
      "[ 4000] loss: 0.317\n",
      "[ 6000] loss: 0.212\n",
      "[ 8000] loss: 0.190\n",
      "[10000] loss: 0.147\n",
      "[12000] loss: 0.137\n",
      "[14000] loss: 0.131\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# loop over the dataset for two times\n",
    "\n",
    "running_loss = 0.0\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "#         print(inputs)\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "        print(f'[{i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "        running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e814f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34407d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  3     4     5     6    \n"
     ]
    }
   ],
   "source": [
    "# Printing the first 4 output or predicted classes\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cfefedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on  10000  test images: 96 %\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy of model on test dataset\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(\"Accuracy of the network on \", total ,\" test images:\", 100*correct//total, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbfa6d32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: 0     is 99.4 %\n",
      "Accuracy for class: 1     is 98.9 %\n",
      "Accuracy for class: 2     is 97.8 %\n",
      "Accuracy for class: 3     is 97.3 %\n",
      "Accuracy for class: 4     is 97.7 %\n",
      "Accuracy for class: 5     is 97.1 %\n",
      "Accuracy for class: 6     is 96.6 %\n",
      "Accuracy for class: 7     is 92.9 %\n",
      "Accuracy for class: 8     is 97.7 %\n",
      "Accuracy for class: 9     is 92.3 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0598b7",
   "metadata": {},
   "source": [
    "There is no much accuracy difference in between the change of kernel sizes, for the first one took kernel size as 5, and for the next one took it as 10. Acccuracy with kernel size 5 is 98% and with kernel size 10 it is 97% <br>\n",
    "\n",
    "Also decreased the for looping over the dataset to see the variation. Only 1% of accuracy difference between 2 times iterating the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3770ff82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
